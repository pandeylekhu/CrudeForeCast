{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests,bs4,string,csv,logging,traceback,os\n",
    "from datetime import datetime\n",
    "def scrape_financial_times(refresh):\n",
    "    logging.basicConfig(filename=\"logs/scrape_financial_times.log\", \n",
    "                    format='%(asctime)s %(message)s', \n",
    "                    filemode='a') \n",
    "    logger=logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    logger.info('Started Scrapping the data')\n",
    "    if refresh.upper()=='Y':\n",
    "        data_file='NewsData/financial_times.csv'\n",
    "        condition=1==1\n",
    "        os.remove(data_file)\n",
    "    else:\n",
    "        arch_data_file='NewsData/financial_times.csv'\n",
    "        data_file='NewsData/financial_times_current.csv'\n",
    "        condition=pageno<2\n",
    "    pageno=1\n",
    "    csv.register_dialect('myDialect',\n",
    "    delimiter = '|',\n",
    "    lineterminator = '\\n',\n",
    "    quoting=csv.QUOTE_NONE,\n",
    "    skipinitialspace=True)\n",
    "    while condition:\n",
    "        if pageno==1:\n",
    "            weblink='https://www.ft.com/oil'\n",
    "        else:\n",
    "            weblink='https://www.ft.com/oil?page='+str(pageno)\n",
    "        fhand=requests.get(weblink)\n",
    "        if (fhand.text=='Maximum page number exceeded'):\n",
    "            break\n",
    "        soup=bs4.BeautifulSoup(fhand.text,'html.parser')\n",
    "        li_lst=soup.findAll('li',{'class':'o-teaser-collection__item o-grid-row'})\n",
    "        with open(data_file, 'a') as f:\n",
    "#             logger.info('Opened file '+data_file)\n",
    "            writer = csv.writer(f, dialect='myDialect')\n",
    "            for li in li_lst:\n",
    "                try:\n",
    "                    if li:\n",
    "                        date_object = datetime.strptime(li.find('time',{'data-o-component':'o-date'}).text, \"%A, %d %B, %Y\")\n",
    "                        writer.writerow([date_object.strftime(\"%d/%m/%Y\"),li.find('div',{'class':'o-teaser__heading'}).text])\n",
    "                except AttributeError as ae:\n",
    "                    None\n",
    "                except UnicodeEncodeError as ue:\n",
    "                    logger.error('Error While getting data from '+weblink+'ERROR:['+traceback.format_exc()+']')\n",
    "        f.close()\n",
    "        fhand.close()\n",
    "        logger.info('Scrapping Completed for '+weblink)\n",
    "        pageno=pageno+1\n",
    "    \n",
    "    if refresh.upper()=='N':\n",
    "        readFile = open(data_file, \"r\")\n",
    "        current_news = fin.read()\n",
    "        readFile.close()\n",
    "        logger.info('Data Read From '+data_file)\n",
    "        writeFile = open(arch_data_file, \"a\")\n",
    "        writeFile.write(current_news)\n",
    "        writeFile.close()\n",
    "        logger.info('Data Appended to '+arch_data_file)\n",
    "    print('completed Successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed Successfully\n"
     ]
    }
   ],
   "source": [
    "scrape_financial_times('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
